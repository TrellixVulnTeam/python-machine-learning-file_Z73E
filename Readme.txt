开源！《Python 机器学习》第二版[python-machine-learning-file]

链接：https://pan.baidu.com/s/1w-RDD7dkGaUJm3L9vFhnrQ 提取码：9e4u

code :https://github.com/rasbt/python-machine-learning-book-2nd-edition

中文翻譯本: https://book.douban.com/subject/27000110/

译者序
推荐序
作者简介
审校者简介
前言
第1章 赋予计算机学习数据的能力1
1.1构建智能机器将数据转化为知识1
1.2 机器学习的三种不同方法1
1.2.1 通过监督学习对未来事件进行预测2
1.2.2 通过强化学习解决交互式问题4
1.2.3 通过无监督学习发现数据本身潜在的结构4
1.2.4 基本术语及符号介绍5
1.3 构建机器学习系统的蓝图6
1.3.1 数据预处理6
1.3.2 选择预测模型类型并进行训练7
1.3.3 模型验证与使用未知数据进行预测8
1.4 Python在机器学习中的应用8
本章小结9
第2章 机器学习分类算法10
2.1 人造神经元—早期机器学习概览10
2.2 使用Python实现感知器学习算法13
2.3 自适应线性神经元及其学习的收敛性19
2.3.1 通过梯度下降最小化代价函数20
2.3.2 使用Python实现自适应线性神经元21
2.3.3 大规模机器学习与随机梯度下降25
本章小结29
第3章 使用scikit-learn实现机器学习分类算法30
3.1 分类算法的选择30
3.2 初涉scikit-learn的使用30
使用scikit-learn训练感知器31
3.3 逻辑斯谛回归中的类别概率34
3.3.1 初识逻辑斯谛回归与条件概率34
3.3.2 通过逻辑斯谛回归模型的代价函数获得权重36
3.3.3 使用scikit-learn训练逻辑斯谛回归模型37
3.3.4 通过正则化解决过拟合问题39
3.4 使用支持向量机最大化分类间隔41
3.4.1 对分类间隔最大化的直观认识41
3.4.2 使用松弛变量解决非线性可分问题42
3.4.3 使用scikit-learn实现SVM44
3.5 使用核SVM解决非线性问题44
3.6 决策树48
3.6.1 最大化信息增益—获知尽可能准确的结果49
3.6.2 构建决策树52
3.6.3 通过随机森林将弱分类器集成为强分类器53
3.7 惰性学习算法—k-近邻算法54
本章小结57
第4章 数据预处理—构建好的训练数据集58
4.1 缺失数据的处理58
4.1.1 将存在缺失值的特征或样本删除59
4.1.2 缺失数据填充60
4.1.3 理解scikit-learn预估器的API60
4.2 处理类别数据61
4.2.1 有序特征的映射61
4.2.2 类标的编码62
4.2.3 标称特征上的独热编码63
4.3 将数据集划分为训练数据集和测试数据集64
4.4 将特征的值缩放到相同的区间65
4.5 选择有意义的特征66
4.5.1 使用L1正则化满足数据稀疏化67
4.5.2 序列特征选择算法70
4.6 通过随机森林判定特征的重要性74
本章小结76
第5章 通过降维压缩数据77
5.1 无监督数据降维技术—主成分分析77
5.1.1 总体方差与贡献方差78
5.1.2 特征转换80
5.1.3 使用scikit-learn进行主成分分析82
5.2 通过线性判别分析压缩无监督数据84
5.2.1 计算散布矩阵85
5.2.2 在新特征子空间上选取线性判别算法87
5.2.3 将样本映射到新的特征空间89
5.2.4 使用scikit-learn进行LDA分析90
5.3 使用核主成分分析进行非线性映射91
5.3.1 核函数与核技巧91
5.3.2 使用Python实现核主成分分析94
5.3.3 映射新的数据点99
5.3.4 scikit-learn中的核主成分分析102
本章小结103
第6章 模型评估与参数调优实战104
6.1 基于流水线的工作流104
6.1.1 加载威斯康星乳腺癌数据集104
6.1.2 在流水线中集成数据转换及评估操作105
6.2 使用k折交叉验证评估模型性能106
6.2.1 holdout方法106
6.2.2 k折交叉验证107
6.3 通过学习及验证曲线来调试算法110
6.3.1 使用学习曲线判定偏差和方差问题110
6.3.2 通过验证曲线来判定过拟合与欠拟合112
6.4 使用网格搜索调优机器学习模型113
6.4.1 使用网络搜索调优超参114
6.4.2 通过嵌套交叉验证选择算法115
6.5 了解不同的性能评价指标116
6.5.1 读取混淆矩阵116
6.5.2 优化分类模型的准确率和召回率117
6.5.3 绘制ROC曲线118
6.5.4 多类别分类的评价标准121
本章小结121
第7章 集成学习—组合不同的模型122
7.1 集成学习122
7.2 实现一个简单的多数投票分类器125
7.3 评估与调优集成分类器131
7.4 bagging —通过bootstrap样本构建集成分类器135
7.5 通过自适应boosting提高弱学习机的性能138
本章小结143
第8章 使用机器学习进行情感分析144
8.1 获取IMDb电影评论数据集144
8.2 词袋模型简介146
8.2.1 将单词转换为特征向量146
8.2.2 通过词频-逆文档频率计算单词关联度147
8.2.3 清洗文本数据148
8.2.4 标记文档149
8.3 训练用于文档分类的逻辑斯谛回归模型151
8.4 使用大数据—在线算法与外存学习152
本章小结155
第9章 在Web应用中嵌入机器学习模型156
9.1 序列化通过scikit-learn拟合的模型156
9.2 使用SQLite数据库存储数据158
9.3 使用Flask开发Web应用160
9.3.1 第一个Flask Web应用160
9.3.2 表单验证及渲染161
9.4 将电影分类器嵌入Web应用164
9.5 在公共服务器上部署Web应用169
本章小结172
第10章 使用回归分析预测连续型目标变量173
10.1 简单线性回归模型初探173
10.2 波士顿房屋数据集174
10.3 基于最小二乘法构建线性回归模型178
10.3.1 通过梯度下降计算回归参数178
10.3.2 使用scikit-learn估计回归模型的系数181
10.4 使用RANSAC拟合高鲁棒性回归模型182
10.5 线性回归模型性能的评估184
10.6 回归中的正则化方法185
10.7 线性回归模型的曲线化-多项式回归186
10.7.1 房屋数据集中的非线性关系建模188
10.7.2 使用随机森林处理非线性关系190
本章小结193
第11章 聚类分析——处理无类标数据194
11.1 使用k-means算法对相似对象进行分组194
11.1.1 k-means++196
11.1.2 硬聚类与软聚类198
11.1.3 使用肘方法确定簇的最佳数量199
11.1.4 通过轮廓图定量分析聚类质量200
11.2 层次聚类203
11.2.1 基于距离矩阵进行层次聚类204
11.2.2 树状图与热度图的关联207
11.2.3 通过scikit-learn进行凝聚聚类208
11.3 使用DBSCAN划分高密度区域209
本章小结212
第12章 使用人工神经网络识别图像213
12.1 使用人工神经网络对复杂函数建模213
12.1.1 单层神经网络回顾214
12.1.2 多层神经网络架构简介215
12.1.3 通过正向传播构造神经网络216
12.2 手写数字的识别218
12.2.1 获取MNIST数据集218
12.2.2 实现一个多层感知器222
12.3 人工神经网络的训练228
12.3.1 计算逻辑斯谛代价函数228
12.3.2 通过反向传播训练神经网络230
12.4 建立对反向传播的直观认识231
12.5 通过梯度检验调试神经网络232
12.6 神经网络的收敛性236
12.7 其他神经网络架构237
12.7.1 卷积神经网络237
12.7.2 循环神经网络238
12.8 关于神经网络的实现239
本章小结240
第13章 使用Theano并行训练神经网络241
13.1 使用Theano构建、编译并运行表达式241
13.1.1 什么是Theano242
13.1.2 初探Theano243
13.1.3 配置Theano244
13.1.4 使用数组结构245
13.1.5 整理思路—线性回归示例247
13.2 为前馈神经网络选择激励函数250
13.2.1 逻辑斯谛函数概述250
13.2.2 通过softmax函数评估多类别分类任务中的类别概率252
13.2.3 通过双曲正切函数增大输出范围252
13.3 使用Keras提高训练神经网络的效率254
本章小结258

---------------

譯者序
推薦序
作者簡介
審校者簡介
前言
第1章 賦予電腦學習資料的能力1
1.1構建智慧型機器將資料轉化為知識1
1.2 機器學習的三種不同方法1
1.2.1 通過監督學習對未來事件進行預測2
1.2.2 通過強化學習解決互動式問題4
1.2.3 通過無監督學習發現資料本身潛在的結構4
1.2.4 基本術語及符號介紹5
1.3 構建機器學習系統的藍圖6
1.3.1 數據預處理6
1.3.2 選擇預測模型類型並進行訓練7
1.3.3 模型驗證與使用未知數據進行預測8
1.4 Python在機器學習中的應用8
本章小結9
第2章 機器學習分類演算法10
2.1 人造神經元—早期機器學習概覽10
2.2 使用Python實現感知器學習演算法13
2.3 自我調整線性神經元及其學習的收斂性19
2.3.1 通過梯度下降最小化代價函數20
2.3.2 使用Python實現自我調整線性神經元21
2.3.3 大規模機器學習與隨機梯度下降25
本章小結29
第3章 使用scikit-learn實現機器學習分類演算法30
3.1 分類演算法的選擇30
3.2 初涉scikit-learn的使用30
使用scikit-learn訓練感知器31
3.3 邏輯斯諦回歸中的類別概率34
3.3.1 初識邏輯斯諦回歸與條件概率34
3.3.2 通過邏輯斯諦回歸模型的代價函數獲得權重36
3.3.3 使用scikit-learn訓練邏輯斯諦回歸模型37
3.3.4 通過正則化解決過擬合問題39
3.4 使用支持向量機最大化分類間隔41
3.4.1 對分類間隔最大化的直觀認識41
3.4.2 使用鬆弛變數解決非線性可分問題42
3.4.3 使用scikit-learn實現SVM44
3.5 使用核SVM解決非線性問題44
3.6 決策樹48
3.6.1 最大化資訊增益—獲知盡可能準確的結果49
3.6.2 構建決策樹52
3.6.3 通過隨機森林將弱分類器集成為強分類器53
3.7 惰性學習演算法—k-近鄰演算法54
本章小結57
第4章 數據預處理—構建好的訓練資料集58
4.1 缺失資料的處理58
4.1.1 將存在缺失值的特徵或樣本刪除59
4.1.2 缺失數據填充60
4.1.3 理解scikit-learn預估器的API60
4.2 處理類別資料61
4.2.1 有序特徵的映射61
4.2.2 類標的編碼62
4.2.3 標稱特徵上的獨熱編碼63
4.3 將資料集劃分為訓練資料集和測試資料集64
4.4 將特徵的值縮放到相同的區間65
4.5 選擇有意義的特徵66
4.5.1 使用L1正則化滿足資料稀疏化67
4.5.2 序列特徵選擇演算法70
4.6 通過隨機森林判定特徵的重要性74
本章小結76
第5章 通過降維壓縮資料77
5.1 無監督資料降維技術—主成分分析77
5.1.1 總體方差與貢獻方差78
5.1.2 特徵轉換80
5.1.3 使用scikit-learn進行主成分分析82
5.2 通過線性判別分析壓縮無監督資料84
5.2.1 計算散佈矩陣85
5.2.2 在新特徵子空間上選取線性判別演算法87
5.2.3 將樣本映射到新的特徵空間89
5.2.4 使用scikit-learn進行LDA分析90
5.3 使用核主成分分析進行非線性映射91
5.3.1 核函數與核技巧91
5.3.2 使用Python實現核主成分分析94
5.3.3 映射新的資料點99
5.3.4 scikit-learn中的核主成分分析102
本章小結103
第6章 模型評估與參數調優實戰104
6.1 基於流水線的工作流104
6.1.1 載入威斯康辛乳腺癌資料集104
6.1.2 在流水線中集成資料轉換及評估操作105
6.2 使用k折交叉驗證評估模型性能106
6.2.1 holdout方法106
6.2.2 k折交叉驗證107
6.3 通過學習及驗證曲線來調試演算法110
6.3.1 使用學習曲線判定偏差和方差問題110
6.3.2 通過驗證曲線來判定過擬合與欠擬合112
6.4 使用網格搜索調優機器學習模型113
6.4.1 使用網路搜索調優超參114
6.4.2 通過嵌套交叉驗證選擇演算法115
6.5 瞭解不同的性能評價指標116
6.5.1 讀取混淆矩陣116
6.5.2 優化分類模型的準確率和召回率117
6.5.3 繪製ROC曲線118
6.5.4 多類別分類的評價標準121
本章小結121
第7章 集成學習—組合不同的模型122
7.1 集成學習122
7.2 實現一個簡單的多數投票分類器125
7.3 評估與調優集成分類器131
7.4 bagging —通過bootstrap樣本構建集成分類器135
7.5 通過自我調整boosting提高弱學習機的性能138
本章小結143
第8章 使用機器學習進行情感分析144
8.1 獲取IMDb電影評論資料集144
8.2 詞袋模型簡介146
8.2.1 將單詞轉換為特徵向量146
8.2.2 通過詞頻-逆文檔頻率計算單詞關聯度147
8.2.3 清洗文本資料148
8.2.4 標記文檔149
8.3 訓練用於文檔分類的邏輯斯諦回歸模型151
8.4 使用大資料—線上演算法與外存學習152
本章小結155
第9章 在Web應用中嵌入機器學習模型156
9.1 序列化通過scikit-learn擬合的模型156
9.2 使用SQLite資料庫存儲資料158
9.3 使用Flask開發Web應用160
9.3.1 第一個Flask Web應用160
9.3.2 表單驗證及渲染161
9.4 將電影分類器嵌入Web應用164
9.5 在公共伺服器上部署Web應用169
本章小結172
第10章 使用回歸分析預測連續型目標變數173
10.1 簡單線性回歸模型初探173
10.2 波士頓房屋資料集174
10.3 基於最小二乘法構建線性回歸模型178
10.3.1 通過梯度下降計算回歸參數178
10.3.2 使用scikit-learn估計回歸模型的係數181
10.4 使用RANSAC擬合高魯棒性回歸模型182
10.5 線性回歸模型性能的評估184
10.6 回歸中的正則化方法185
10.7 線性回歸模型的曲線化-多項式回歸186
10.7.1 房屋資料集中的非線性關係建模188
10.7.2 使用隨機森林處理非線性關係190
本章小結193
第11章 聚類分析——處理無類標資料194
11.1 使用k-means演算法對相似物件進行分組194
11.1.1 k-means++196
11.1.2 硬聚類與軟聚類198
11.1.3 使用肘方法確定簇的最佳數量199
11.1.4 通過輪廓圖定量分析聚類品質200
11.2 層次聚類203
11.2.1 基於距離矩陣進行層次聚類204
11.2.2 樹狀圖與熱度圖的關聯207
11.2.3 通過scikit-learn進行凝聚聚類208
11.3 使用DBSCAN劃分高密度區域209
本章小結212
第12章 使用人工神經網路識別圖像213
12.1 使用人工神經網路對複雜函數建模213
12.1.1 單層神經網路回顧214
12.1.2 多層神經網路架構簡介215
12.1.3 通過正向傳播構造神經網路216
12.2 手寫數位的識別218
12.2.1 獲取MNIST資料集218
12.2.2 實現一個多層感知器222
12.3 人工神經網路的訓練228
12.3.1 計算邏輯斯諦代價函數228
12.3.2 通過反向傳播訓練神經網路230
12.4 建立對反向傳播的直觀認識231
12.5 通過梯度檢驗調試神經網路232
12.6 神經網路的收斂性236
12.7 其他神經網路架構237
12.7.1 卷積神經網路237
12.7.2 迴圈神經網路238
12.8 關於神經網路的實現239
本章小結240
第13章 使用Theano並行訓練神經網路241
13.1 使用Theano構建、編譯並運行運算式241
13.1.1 什麼是Theano242
13.1.2 初探Theano243
13.1.3 配置Theano244
13.1.4 使用陣列結構245
13.1.5 整理思路—線性回歸示例247
13.2 為前饋神經網路選擇激勵函數250
13.2.1 邏輯斯諦函數概述250
13.2.2 通過softmax函數評估多類別分類任務中的類別概率252
13.2.3 通過雙曲正切函數增大輸出範圍252
13.3 使用Keras提高訓練神經網路的效率254
本章小結258
